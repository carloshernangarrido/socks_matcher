{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to the zip file and the extraction directory\n",
    "zip_file_path = 'initial_annotation.zip'\n",
    "extract_dir = 'initial_annotation'\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(\"Extraction complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations loaded!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to the annotations file\n",
    "annotations_file = os.path.join(extract_dir, 'result.json')\n",
    "\n",
    "# Load the annotations\n",
    "with open(annotations_file, 'r') as f:\n",
    "    coco_annotations = json.load(f)\n",
    "\n",
    "print(\"Annotations loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking and cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "def create_mask(segmentation, width, height):\n",
    "    mask = Image.new('L', (width, height), 0)\n",
    "    for polygon in segmentation:\n",
    "        ImageDraw.Draw(mask).polygon(polygon, outline=1, fill=1)\n",
    "    return mask\n",
    "\n",
    "def crop_and_paste(coco_annotations, image_dir, background_image_path, output_dir, scale: float = 0.1, \n",
    "                   loc: tuple[float, float] = (0., 0.), output_size: tuple[int, int] = (300, 300), \n",
    "                   offset_callback: callable = lambda: (100, 100),\n",
    "                   aug_idx: int = 0):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the background image\n",
    "    background_image = Image.open(background_image_path)\n",
    "\n",
    "    # Loop over each annotation\n",
    "    for i_ann, annotation in enumerate(coco_annotations['annotations']):\n",
    "        # Load the image\n",
    "        image_info = next(image for image in coco_annotations['images'] if image['id'] == annotation['image_id'])\n",
    "        image_path = os.path.join(image_dir, image_info['file_name'])\n",
    "        image = Image.open(image_path)\n",
    "        # plt.figure()\n",
    "        # plt.imshow(np.array(image))\n",
    "        # plt.show()\n",
    "\n",
    "        # Create a mask from the segmentation data\n",
    "        segmentation = annotation['segmentation']\n",
    "        width, height = image_info['width'], image_info['height']\n",
    "        mask = create_mask(segmentation, width, height)\n",
    "        # plt.figure()\n",
    "        # plt.imshow(np.array(mask))\n",
    "        # plt.show()\n",
    "\n",
    "        # Apply the mask to the image to get the cropped object\n",
    "        image_array = np.array(image)\n",
    "        mask_array = np.array(mask)\n",
    "        cropped_image_array = np.zeros_like(image_array)\n",
    "        for i in range(3):  # For each color channel\n",
    "            cropped_image_array[:, :, i] = image_array[:, :, i] * mask_array\n",
    "        cropped_image = Image.fromarray(cropped_image_array)\n",
    "        # plt.figure()\n",
    "        # plt.imshow(np.array(cropped_image))\n",
    "        # plt.show()\n",
    "\n",
    "        # Restric the cropped image to the boundingbox\n",
    "        bbox = [int(_) for _ in annotation['bbox']]\n",
    "        bbox_cropped_image = Image.fromarray(np.array(cropped_image)[bbox[1]:bbox[1]+bbox[3], bbox[0]:bbox[0]+bbox[2]])\n",
    "        bbox_mask = Image.fromarray(np.array(mask)[bbox[1]:bbox[1]+bbox[3], bbox[0]:bbox[0]+bbox[2]]*255)\n",
    "        # plt.figure()\n",
    "        # plt.imshow(np.array(bbox_cropped_image))\n",
    "        # plt.show()\n",
    "        # plt.figure()\n",
    "        # plt.imshow(np.array(bbox_mask))\n",
    "        # plt.show()\n",
    "\n",
    "        # Resize\n",
    "        width = int(scale*background_image.width)\n",
    "        height = int(bbox_cropped_image.height * (width/bbox_cropped_image.width))\n",
    "        bbox_cropped_image = bbox_cropped_image.resize((width, height))\n",
    "        bbox_mask = bbox_mask.resize((width, height))\n",
    "\n",
    "        # Paste the cropped image onto the background image\n",
    "        background_copy = background_image.copy()\n",
    "        loc_in_bg = (int(loc[0]*background_copy.width), int(loc[1]*background_copy.height))\n",
    "        background_copy.paste(bbox_cropped_image, loc_in_bg, bbox_mask)\n",
    "        offset = offset_callback()\n",
    "        pasted = background_copy.crop((loc_in_bg[0]-offset[0], loc_in_bg[1]-offset[1], \n",
    "                                       loc_in_bg[0]-offset[0]+output_size[1], loc_in_bg[1]-offset[1]+output_size[1]))\n",
    "        # plt.figure()\n",
    "        # plt.imshow(np.array(pasted))\n",
    "        # plt.show()\n",
    "\n",
    "        # Generate mask\n",
    "        mask_copy = Image.fromarray(0*np.array(background_image.copy()))\n",
    "        mask_copy.paste(bbox_mask, loc_in_bg, bbox_mask)\n",
    "        mask_pasted = mask_copy.crop((loc_in_bg[0]-offset[0], loc_in_bg[1]-offset[1], \n",
    "                                       loc_in_bg[0]-offset[0]+output_size[1], loc_in_bg[1]-offset[1]+output_size[1]))\n",
    "        # plt.figure()\n",
    "        # plt.imshow(np.array(mask_pasted))\n",
    "        # plt.show()\n",
    "\n",
    "        # Save the resulting image\n",
    "        name = os.path.split(image_info['file_name'])[-1]\n",
    "        output_path = os.path.join(output_dir, f\"pasted_{aug_idx}_{i_ann}_{name}\")\n",
    "        pasted.save(output_path)\n",
    "\n",
    "        # Save mask\n",
    "        name = os.path.split(image_info['file_name'])[-1]\n",
    "        output_path = os.path.join(output_dir, f\"mask_{aug_idx}_{i_ann}_{name}\")\n",
    "        mask_pasted.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "image_dir = 'initial_annotation'\n",
    "output_dir = 'pasted'\n",
    "\n",
    "background_image_paths = [f'backgrounds/bg{_+1}.jpg' for _ in range(6)]\n",
    "scales = [0.10, 0.15, 0.20]\n",
    "locs = [(0.1, 0.1), (0.1, 0.3), (0.1, 0.5),\n",
    "        (0.3, 0.1), (0.3, 0.3), (0.3, 0.5),\n",
    "        (0.5, 0.1), (0.5, 0.3), (0.5, 0.5)]\n",
    "\n",
    "# Crop and paste images\n",
    "aug_idx = 0\n",
    "for background_image_path in background_image_paths:\n",
    "    for scale in scales:\n",
    "        for loc in locs:\n",
    "            offset_callback = lambda: (int(np.random.uniform(0,128)), int(np.random.uniform(0,128)))\n",
    "            crop_and_paste(coco_annotations, image_dir, background_image_path, output_dir, scale=scale, loc=loc, \n",
    "                           output_size=(256,256), offset_callback=offset_callback, aug_idx=aug_idx)\n",
    "            aug_idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
